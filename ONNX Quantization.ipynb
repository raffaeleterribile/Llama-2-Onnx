{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX Model quantization\n",
    "\n",
    "I'll try to take a LlaMa ONNX model and convert it to a Int8 quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime.quantization.preprocess as preprocess\n",
    "import onnxruntime.quantization as quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Incomplete symbolic shape inference",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Progetti\\VisualStudioCode\\Llama-2-Onnx\\ONNX Quantization.ipynb Cella 3\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Progetti/VisualStudioCode/Llama-2-Onnx/ONNX%20Quantization.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model_input \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m7B_FT_float16/ONNX/LlamaV2_7B_FT_float16.onnx\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Progetti/VisualStudioCode/Llama-2-Onnx/ONNX%20Quantization.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model_preprocessed \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m7B_FT_int8/ONNX/LlamaV2_7B_FT_int16_preprocessed.onnx\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Progetti/VisualStudioCode/Llama-2-Onnx/ONNX%20Quantization.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m preprocess\u001b[39m.\u001b[39;49mquant_pre_process(input_model_path \u001b[39m=\u001b[39;49m model_input, output_model_path\u001b[39m=\u001b[39;49mmodel_preprocessed, skip_optimization\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\Raffaele\\.conda\\envs\\llamachat\\lib\\site-packages\\onnxruntime\\quantization\\shape_inference.py:71\u001b[0m, in \u001b[0;36mquant_pre_process\u001b[1;34m(input_model_path, output_model_path, skip_optimization, skip_onnx_shape, skip_symbolic_shape, auto_merge, int_max, guess_output_rank, verbose, save_as_external_data, all_tensors_to_one_file, external_data_location, external_data_size_threshold)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m skip_symbolic_shape:\n\u001b[0;32m     70\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mPerforming symbolic shape inference...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 71\u001b[0m     model \u001b[39m=\u001b[39m SymbolicShapeInference\u001b[39m.\u001b[39;49minfer_shapes(\n\u001b[0;32m     72\u001b[0m         onnx\u001b[39m.\u001b[39;49mload(input_model_path),\n\u001b[0;32m     73\u001b[0m         int_max,\n\u001b[0;32m     74\u001b[0m         auto_merge,\n\u001b[0;32m     75\u001b[0m         guess_output_rank,\n\u001b[0;32m     76\u001b[0m         verbose,\n\u001b[0;32m     77\u001b[0m     )\n\u001b[0;32m     79\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m skip_optimization:\n\u001b[0;32m     80\u001b[0m     \u001b[39m# Use ORT optimizers (native code) to optimize model\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m skip_symbolic_shape:\n\u001b[0;32m     82\u001b[0m         \u001b[39m# Need to save the inferenced model to file so as to run the optimizer\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Raffaele\\.conda\\envs\\llamachat\\lib\\site-packages\\onnxruntime\\tools\\symbolic_shape_infer.py:2822\u001b[0m, in \u001b[0;36mSymbolicShapeInference.infer_shapes\u001b[1;34m(in_mp, int_max, auto_merge, guess_output_rank, verbose)\u001b[0m\n\u001b[0;32m   2820\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m all_shapes_inferred:\n\u001b[0;32m   2821\u001b[0m     onnx\u001b[39m.\u001b[39msave_model(symbolic_shape_inference\u001b[39m.\u001b[39mout_mp_, \u001b[39m\"\u001b[39m\u001b[39msym_shape_infer_temp.onnx\u001b[39m\u001b[39m\"\u001b[39m, save_as_external_data\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m-> 2822\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIncomplete symbolic shape inference\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2823\u001b[0m \u001b[39mreturn\u001b[39;00m symbolic_shape_inference\u001b[39m.\u001b[39mout_mp_\n",
      "\u001b[1;31mException\u001b[0m: Incomplete symbolic shape inference"
     ]
    }
   ],
   "source": [
    "# Path for input and output\n",
    "model_input = '7B_FT_float16/ONNX/LlamaV2_7B_FT_float16.onnx'\n",
    "model_preprocessed = '7B_FT_int8/ONNX/LlamaV2_7B_FT_int16_preprocessed.onnx'\n",
    "\n",
    "preprocess.quant_pre_process(input_model_path = model_input, output_model_path=model_preprocessed, skip_optimization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\Progetti\\VisualStudioCode\\Llama-2-Onnx\\ONNX Quantization.ipynb Cella 4\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Progetti/VisualStudioCode/Llama-2-Onnx/ONNX%20Quantization.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Quantize the model to int8\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Progetti/VisualStudioCode/Llama-2-Onnx/ONNX%20Quantization.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m config \u001b[39m=\u001b[39m quantization\u001b[39m.\u001b[39mDynamicQuantConfig()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Progetti/VisualStudioCode/Llama-2-Onnx/ONNX%20Quantization.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m quantization\u001b[39m.\u001b[39;49mquantize(model_input\u001b[39m=\u001b[39;49mmodel_input, model_output\u001b[39m=\u001b[39;49mmodel_output, quant_config\u001b[39m=\u001b[39;49mconfig)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Progetti/VisualStudioCode/Llama-2-Onnx/ONNX%20Quantization.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mQuantization completed successfully.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Raffaele\\.conda\\envs\\llamachat\\lib\\site-packages\\onnxruntime\\quantization\\quantize.py:617\u001b[0m, in \u001b[0;36mquantize\u001b[1;34m(model_input, model_output, quant_config)\u001b[0m\n\u001b[0;32m    599\u001b[0m     quantize_static(\n\u001b[0;32m    600\u001b[0m         model_input,\n\u001b[0;32m    601\u001b[0m         model_output,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    613\u001b[0m         extra_options\u001b[39m=\u001b[39mquant_config\u001b[39m.\u001b[39mextra_options,\n\u001b[0;32m    614\u001b[0m     )\n\u001b[0;32m    616\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(quant_config, DynamicQuantConfig):\n\u001b[1;32m--> 617\u001b[0m     quantize_dynamic(\n\u001b[0;32m    618\u001b[0m         model_input,\n\u001b[0;32m    619\u001b[0m         model_output,\n\u001b[0;32m    620\u001b[0m         weight_type\u001b[39m=\u001b[39;49mquant_config\u001b[39m.\u001b[39;49mweight_type,\n\u001b[0;32m    621\u001b[0m         op_types_to_quantize\u001b[39m=\u001b[39;49mquant_config\u001b[39m.\u001b[39;49mop_types_to_quantize,\n\u001b[0;32m    622\u001b[0m         nodes_to_quantize\u001b[39m=\u001b[39;49mquant_config\u001b[39m.\u001b[39;49mnodes_to_quantize,\n\u001b[0;32m    623\u001b[0m         nodes_to_exclude\u001b[39m=\u001b[39;49mquant_config\u001b[39m.\u001b[39;49mnodes_to_exclude,\n\u001b[0;32m    624\u001b[0m         per_channel\u001b[39m=\u001b[39;49mquant_config\u001b[39m.\u001b[39;49mper_channel,\n\u001b[0;32m    625\u001b[0m         reduce_range\u001b[39m=\u001b[39;49mquant_config\u001b[39m.\u001b[39;49mreduce_range,\n\u001b[0;32m    626\u001b[0m         use_external_data_format\u001b[39m=\u001b[39;49mquant_config\u001b[39m.\u001b[39;49muse_external_data_format,\n\u001b[0;32m    627\u001b[0m         extra_options\u001b[39m=\u001b[39;49mquant_config\u001b[39m.\u001b[39;49mextra_options,\n\u001b[0;32m    628\u001b[0m     )\n\u001b[0;32m    629\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    630\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid quantization config type, it must be either StaticQuantConfig or DynamicQuantConfig.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Raffaele\\.conda\\envs\\llamachat\\lib\\site-packages\\onnxruntime\\quantization\\quantize.py:582\u001b[0m, in \u001b[0;36mquantize_dynamic\u001b[1;34m(model_input, model_output, op_types_to_quantize, per_channel, reduce_range, weight_type, nodes_to_quantize, nodes_to_exclude, use_external_data_format, extra_options)\u001b[0m\n\u001b[0;32m    566\u001b[0m quantizer \u001b[39m=\u001b[39m ONNXQuantizer(\n\u001b[0;32m    567\u001b[0m     model,\n\u001b[0;32m    568\u001b[0m     per_channel,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    578\u001b[0m     extra_options,\n\u001b[0;32m    579\u001b[0m )\n\u001b[0;32m    581\u001b[0m quantizer\u001b[39m.\u001b[39mquantize_model()\n\u001b[1;32m--> 582\u001b[0m quantizer\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49msave_model_to_file(model_output, use_external_data_format)\n",
      "File \u001b[1;32mc:\\Users\\Raffaele\\.conda\\envs\\llamachat\\lib\\site-packages\\onnxruntime\\quantization\\onnx_model.py:360\u001b[0m, in \u001b[0;36mONNXModel.save_model_to_file\u001b[1;34m(self, output_path, use_external_data_format)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[39mfor\u001b[39;00m init \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39minitializer:\n\u001b[0;32m    359\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_init(init, \u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 360\u001b[0m onnx\u001b[39m.\u001b[39;49msave_model(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, output_path)\n",
      "File \u001b[1;32mc:\\Users\\Raffaele\\.conda\\envs\\llamachat\\lib\\site-packages\\onnx\\__init__.py:326\u001b[0m, in \u001b[0;36msave_model\u001b[1;34m(proto, f, format, save_as_external_data, all_tensors_to_one_file, location, size_threshold, convert_attribute)\u001b[0m\n\u001b[0;32m    323\u001b[0m     basepath \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(model_filepath)\n\u001b[0;32m    324\u001b[0m     proto \u001b[39m=\u001b[39m write_external_data_tensors(proto, basepath)\n\u001b[1;32m--> 326\u001b[0m serialized \u001b[39m=\u001b[39m _get_serializer(\u001b[39mformat\u001b[39;49m, model_filepath)\u001b[39m.\u001b[39;49mserialize_proto(proto)\n\u001b[0;32m    327\u001b[0m _save_bytes(serialized, f)\n",
      "File \u001b[1;32mc:\\Users\\Raffaele\\.conda\\envs\\llamachat\\lib\\site-packages\\onnx\\serialization.py:100\u001b[0m, in \u001b[0;36m_ProtobufSerializer.serialize_proto\u001b[1;34m(self, proto)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(proto, \u001b[39m\"\u001b[39m\u001b[39mSerializeToString\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mcallable\u001b[39m(proto\u001b[39m.\u001b[39mSerializeToString):\n\u001b[0;32m     99\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 100\u001b[0m         result \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39;49mSerializeToString()\n\u001b[0;32m    101\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    102\u001b[0m         \u001b[39mif\u001b[39;00m proto\u001b[39m.\u001b[39mByteSize() \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m onnx\u001b[39m.\u001b[39mchecker\u001b[39m.\u001b[39mMAXIMUM_PROTOBUF:\n",
      "File \u001b[1;32mc:\\Users\\Raffaele\\.conda\\envs\\llamachat\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py:1086\u001b[0m, in \u001b[0;36m_AddSerializeToStringMethod.<locals>.SerializeToString\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1082\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mIsInitialized():\n\u001b[0;32m   1083\u001b[0m   \u001b[39mraise\u001b[39;00m message_mod\u001b[39m.\u001b[39mEncodeError(\n\u001b[0;32m   1084\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mMessage \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is missing required fields: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (\n\u001b[0;32m   1085\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mDESCRIPTOR\u001b[39m.\u001b[39mfull_name, \u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mFindInitializationErrors())))\n\u001b[1;32m-> 1086\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mSerializePartialToString(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Raffaele\\.conda\\envs\\llamachat\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py:1095\u001b[0m, in \u001b[0;36m_AddSerializePartialToStringMethod.<locals>.SerializePartialToString\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1093\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mSerializePartialToString\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1094\u001b[0m   out \u001b[39m=\u001b[39m BytesIO()\n\u001b[1;32m-> 1095\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_InternalSerialize(out\u001b[39m.\u001b[39mwrite, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1096\u001b[0m   \u001b[39mreturn\u001b[39;00m out\u001b[39m.\u001b[39mgetvalue()\n",
      "File \u001b[1;32mc:\\Users\\Raffaele\\.conda\\envs\\llamachat\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py:1115\u001b[0m, in \u001b[0;36m_AddSerializePartialToStringMethod.<locals>.InternalSerialize\u001b[1;34m(self, write_bytes, deterministic)\u001b[0m\n\u001b[0;32m   1113\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1114\u001b[0m   \u001b[39mfor\u001b[39;00m field_descriptor, field_value \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mListFields():\n\u001b[1;32m-> 1115\u001b[0m     field_descriptor\u001b[39m.\u001b[39;49m_encoder(write_bytes, field_value, deterministic)\n\u001b[0;32m   1116\u001b[0m   \u001b[39mfor\u001b[39;00m tag_bytes, value_bytes \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unknown_fields:\n\u001b[0;32m   1117\u001b[0m     write_bytes(tag_bytes)\n",
      "File \u001b[1;32mc:\\Users\\Raffaele\\.conda\\envs\\llamachat\\lib\\site-packages\\google\\protobuf\\internal\\encoder.py:768\u001b[0m, in \u001b[0;36mMessageEncoder.<locals>.EncodeField\u001b[1;34m(write, value, deterministic)\u001b[0m\n\u001b[0;32m    766\u001b[0m write(tag)\n\u001b[0;32m    767\u001b[0m local_EncodeVarint(write, value\u001b[39m.\u001b[39mByteSize(), deterministic)\n\u001b[1;32m--> 768\u001b[0m \u001b[39mreturn\u001b[39;00m value\u001b[39m.\u001b[39;49m_InternalSerialize(write, deterministic)\n",
      "File \u001b[1;32mc:\\Users\\Raffaele\\.conda\\envs\\llamachat\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py:1115\u001b[0m, in \u001b[0;36m_AddSerializePartialToStringMethod.<locals>.InternalSerialize\u001b[1;34m(self, write_bytes, deterministic)\u001b[0m\n\u001b[0;32m   1113\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1114\u001b[0m   \u001b[39mfor\u001b[39;00m field_descriptor, field_value \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mListFields():\n\u001b[1;32m-> 1115\u001b[0m     field_descriptor\u001b[39m.\u001b[39;49m_encoder(write_bytes, field_value, deterministic)\n\u001b[0;32m   1116\u001b[0m   \u001b[39mfor\u001b[39;00m tag_bytes, value_bytes \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unknown_fields:\n\u001b[0;32m   1117\u001b[0m     write_bytes(tag_bytes)\n",
      "File \u001b[1;32mc:\\Users\\Raffaele\\.conda\\envs\\llamachat\\lib\\site-packages\\google\\protobuf\\internal\\encoder.py:762\u001b[0m, in \u001b[0;36mMessageEncoder.<locals>.EncodeRepeatedField\u001b[1;34m(write, value, deterministic)\u001b[0m\n\u001b[0;32m    760\u001b[0m write(tag)\n\u001b[0;32m    761\u001b[0m local_EncodeVarint(write, element\u001b[39m.\u001b[39mByteSize(), deterministic)\n\u001b[1;32m--> 762\u001b[0m element\u001b[39m.\u001b[39;49m_InternalSerialize(write, deterministic)\n",
      "File \u001b[1;32mc:\\Users\\Raffaele\\.conda\\envs\\llamachat\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py:1115\u001b[0m, in \u001b[0;36m_AddSerializePartialToStringMethod.<locals>.InternalSerialize\u001b[1;34m(self, write_bytes, deterministic)\u001b[0m\n\u001b[0;32m   1113\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1114\u001b[0m   \u001b[39mfor\u001b[39;00m field_descriptor, field_value \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mListFields():\n\u001b[1;32m-> 1115\u001b[0m     field_descriptor\u001b[39m.\u001b[39;49m_encoder(write_bytes, field_value, deterministic)\n\u001b[0;32m   1116\u001b[0m   \u001b[39mfor\u001b[39;00m tag_bytes, value_bytes \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unknown_fields:\n\u001b[0;32m   1117\u001b[0m     write_bytes(tag_bytes)\n",
      "File \u001b[1;32mc:\\Users\\Raffaele\\.conda\\envs\\llamachat\\lib\\site-packages\\google\\protobuf\\internal\\encoder.py:726\u001b[0m, in \u001b[0;36mBytesEncoder.<locals>.EncodeField\u001b[1;34m(write, value, deterministic)\u001b[0m\n\u001b[0;32m    724\u001b[0m write(tag)\n\u001b[0;32m    725\u001b[0m local_EncodeVarint(write, local_len(value), deterministic)\n\u001b[1;32m--> 726\u001b[0m \u001b[39mreturn\u001b[39;00m write(value)\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_output = '7B_FT_int8/ONNX/LlamaV2_7B_FT_int8.onnx'\n",
    "\n",
    "# Quantize the model to int8\n",
    "quant_config = quantization.DynamicQuantConfig()\n",
    "quantization.quantize(model_input=model_input, model_output=model_output, quant_config=quant_config)\n",
    "\n",
    "print(\"Quantization completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original ONNX model\n",
    "# model_path = '7B_FT_float16/ONNX/LlamaV2_7B_FT_float16.onnx'\n",
    "# model = onnx.load(model_path)\n",
    "\n",
    "# Quantize the model to int8\n",
    "# quantized_model = quantization.quantize(model, quantization_mode='int4')\n",
    "\n",
    "# Save the quantized model\n",
    "# quantized_model_path = '7B_FT_int4/ONNX/LlamaV2_7B_FT_int4.onnx'\n",
    "# onnx.save(quantized_model, quantized_model_path)\n",
    "\n",
    "# print(\"Quantization completed successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamachat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
